# source:
# https://t37.net/how-we-reindexed-36-billion-documents-in-5-days-within-the-same-elasticsearch-cluster.html
# https://github.com/elastic/curator/issues/497#issuecomment-283399689
input {
  elasticsearch {
    hosts => [ "source-elasticsearch:9200" ]
    index => "source-index"
    size => 5000
    scroll => "20m" # 5 minutes initial
    docinfo => true
    query => '{ "query": { "range": { "date": { "gte": "2015-07-23T10:00.000+01:00", "lte": "2015-07-23T11:00.000+01:00" } } } }'
  }
}
output {
  elasticsearch {
    host => "destination-elasticsearch:9200"
    index => "destination-elasticsearch:9200"
    protocol => "http"
    index_type => "%{[@metadata][_type]}"
    document_id => "%{[@metadata][_id]}"
    workers => 10
  }
  stdout {
    codec => rubydebug # because removing the timestamp field makes logstash crash
  }
}
filter {
  mutate {
    rename => { "some field" => "some other field" }
    rename => { "another field" => "somewhere else" }
    remove_field => [ "something", "something else", "another field", "some field", "@timestamp", "@version" ]
  }
}